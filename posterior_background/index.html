<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Background · FittingObjectiveFunctions</title><meta name="title" content="Background · FittingObjectiveFunctions"/><meta property="og:title" content="Background · FittingObjectiveFunctions"/><meta property="twitter:title" content="Background · FittingObjectiveFunctions"/><meta name="description" content="Documentation for FittingObjectiveFunctions."/><meta property="og:description" content="Documentation for FittingObjectiveFunctions."/><meta property="twitter:description" content="Documentation for FittingObjectiveFunctions."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.svg" alt="FittingObjectiveFunctions logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">FittingObjectiveFunctions</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">FittingObjectiveFunctions</a></li><li><a class="tocitem" href="../fitting_data/">FittingData and ModelFunctions</a></li><li><span class="tocitem">Least squares objective</span><ul><li><a class="tocitem" href="../lsq_background/">Background</a></li><li><a class="tocitem" href="../lsq_implementation/">How to implement</a></li></ul></li><li><span class="tocitem">Posterior probability</span><ul><li class="is-active"><a class="tocitem" href>Background</a><ul class="internal"><li><a class="tocitem" href="#Applying-Bayes&#39;-theorem"><span>Applying Bayes&#39; theorem</span></a></li><li><a class="tocitem" href="#Independent-data-points"><span>Independent data points</span></a></li><li><a class="tocitem" href="#No-x-uncertainty"><span>No <span>$x$</span>-uncertainty</span></a></li><li><a class="tocitem" href="#Retrieving-the-LSQ-objective"><span>Retrieving the LSQ objective</span></a></li></ul></li><li><a class="tocitem" href="../posterior_implementation/">How to implement</a></li></ul></li><li><span class="tocitem">Logarithmic posterior probability</span><ul><li><a class="tocitem" href="../log_posterior_background/">Background</a></li><li><a class="tocitem" href="../log_posterior_implementation/">How to implement</a></li></ul></li><li><a class="tocitem" href="../API/">API</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Posterior probability</a></li><li class="is-active"><a href>Background</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Background</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/AntibodyPackages/FittingObjectiveFunctions" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/AntibodyPackages/FittingObjectiveFunctions/blob/main/docs/src/posterior_background.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Background:-Posterior-probability"><a class="docs-heading-anchor" href="#Background:-Posterior-probability">Background: Posterior probability</a><a id="Background:-Posterior-probability-1"></a><a class="docs-heading-anchor-permalink" href="#Background:-Posterior-probability" title="Permalink"></a></h1><p>The posterior objective (and the <a href="#Log-posterior-objective">Log posterior objective</a> which is numerically favorable) allows to define more general objective functions. Form a Bayesian perspective, one is interested in the probability density for a particular parameter <span>$\lambda$</span> given the data <span>$\{x_i\}_{i=1}^N, \{y_i\}_{i=1}^N$</span> and the model <span>$m(x,\lambda)$</span>:</p><p class="math-container">\[p(\lambda \mid \{x_i\}_{i=1}^N, \{y_i\}_{i=1}^N, m)\]</p><h2 id="Applying-Bayes&#39;-theorem"><a class="docs-heading-anchor" href="#Applying-Bayes&#39;-theorem">Applying Bayes&#39; theorem</a><a id="Applying-Bayes&#39;-theorem-1"></a><a class="docs-heading-anchor-permalink" href="#Applying-Bayes&#39;-theorem" title="Permalink"></a></h2><p>Using Bayes&#39; theorem, the probability density can be rewritten as:</p><p class="math-container">\[p(\lambda \mid \{x_i\}_{i=1}^N, \{y_i\}_{i=1}^N, m) = \frac{\ell(\{y_i\}_{i=1}^N \mid \{x_i\}_{i=1}^N , \lambda, m )\cdot p_0(\lambda\mid \{x_i\}_{i=1}^N, m)}{p(\{y_i\}_{i=1}^N \mid \{x_i\}_{i=1}^N , m)}\]</p><p>The denominator is but a normalization constant, that does not depend on <span>$\lambda$</span>, i.e. can be ignored for optimization problems (and MCMC sampling):</p><p class="math-container">\[p(\lambda \mid \{x_i\}_{i=1}^N, \{y_i\}_{i=1}^N, m) \propto \ell(\{y_i\}_{i=1}^N \mid \{x_i\}_{i=1}^N , \lambda, m )\cdot p_0(\lambda\mid \{x_i\}_{i=1}^N, m)\]</p><p>Because of the proportionality, one may refer to the right hand side as <strong>unnormalized posterior</strong>.</p><ul><li><p><span>$\ell$</span> is a proper probability distribution for <span>$\{y_i\}_{i=1}^N$</span> given <span>$\{x_i\}_{i=1}^N, \lambda, m$</span>. However, it can also be regarded as function of <span>$\lambda$</span>, for fixed <span>$\{x_i\}_{i=1}^N$</span>, <span>$\{y_i\}_{i=1}^N$</span> and <span>$m$</span> (which is needed, since the data is fixed, but different parameters need to be tested for model fitting). In this case, one calls it the <strong>likelihood</strong> function of <span>$\lambda$</span>. It is no longer a proper probability density (still positive but no longer normalized).</p></li><li><p><span>$p_0$</span> is the so called <strong>prior</strong> distribution. It determines the probability of the parameters, before the data was obtained. This is sometimes called <em>belief in parameters</em> or <em>initial knowledge</em>.</p></li></ul><div class="admonition is-category-default"><header class="admonition-header">The prior and objectivity</header><div class="admonition-body"><p>A common critique is, that the prior is not objective. While the choice of prior can be subjective, it must be explicitly stated making all assumptions transparent. This allows for an objective comparison of the different approaches.</p><p>In fact, there are two common types of priors in least squares fitting.</p><ol><li><p><span>$p_0(\lambda\mid \{x_i\}_{i=1}^N, m) = 1$</span>, i.e. a uniform prior. Since one usually uses a computer, there is a largest number <span>$b &lt;\infty$</span> and a smallest number <span>$a &gt; -\infty$</span> that the computer can use. Then one may choose the uniform distribution <span>$p_0(\lambda \mid \{x_i\}_{i=1}^N, m) = \frac{1}{b-a}$</span>. Sine the posterior probability is only considered up to proportionality, one can simply use <span>$p_0(\lambda\mid \{x_i\}_{i=1}^N, m) = 1$</span>. This leads to a <strong>maximum likelihood</strong> objective.</p></li><li><p>In ill-defined problems, it is common practice to use some kind of regularization. In some cases, these regularizations correspond to certain priors. For example, the Tikhonov regularization essentially uses the prior <span>$p_0(\lambda\mid \{x_i\}_{i=1}^N, m) \propto \exp(-||\Gamma \lambda ||^2)$</span>.</p></li></ol></div></div><h2 id="Independent-data-points"><a class="docs-heading-anchor" href="#Independent-data-points">Independent data points</a><a id="Independent-data-points-1"></a><a class="docs-heading-anchor-permalink" href="#Independent-data-points" title="Permalink"></a></h2><p>A common assumption is that the data points are independent. While this is not a necessity, writing general likelihood functions is usually not trivial. If the data points are independent, the likelihood function becomes a product of likelihood functions for the individual data point likelihoods:</p><p class="math-container">\[\ell(\{y_i\}_{i=1}^N \mid \lambda, \{x_i\}_{i=1}^N m ) = \prod_{i=1}^N \ell_i(y_i\mid \lambda, x_i, m)\]</p><p>Note that the likelihoods can differ for the different data points, denoted by <span>$\ell_i$</span> here.  Thus the posterior probability / the objective function becomes</p><p class="math-container">\[p(\lambda \mid \{x_i\}_{i=1}^N, \{y_i\}_{i=1}^N, m) \propto  p_0(\lambda\mid \{x_i\}_{i=1}^N, m) \prod_{i_1}^n \ell_i(y_i\mid \lambda, x_i,m)\]</p><p>In general, <span>$x_i$</span> is only the measured value, while the true value <span>$\mathcal{X}_i$</span> is unknown. If the distribution <span>$p_i(\mathcal{X}_i\mid \lambda, x_i, m)$</span> is known, marginalization can be used to express the likelihood</p><p class="math-container">\[\ell(y_i\mid \lambda, x_i, m) = \int \ell(y_i \mid \mathcal{X}_i, \lambda, x_i, m)\cdot p(\mathcal{X}_i\mid \lambda, x_i,m) \ d\mathcal{X}_i\]</p><p>It can happen, that this integral can only be solved numerically. Since this is computationally expensive, and needs to be redone for every new value of <span>$\lambda$</span>, the resulting posterior distribution is often not suited for optimization/sampling purposes. Another approach could be data-augmentation, e.g. to sample <span>$\ell(y_i, \mathcal{X}_i\mid \lambda, x_i, m)$</span>, which is not the scope of this package.</p><p>The likelihood <span>$\ell(y_i\mid \mathcal{X}_i, \lambda, x_i, m)$</span> is essentially given by the probability distribution <span>$q_i(y_i\mid \mathcal{Y}_i)$</span> to measure <span>$y_i$</span> when the true value is <span>$\mathcal{Y}_i$</span>, since <span>$\mathcal{Y}_i = m(\mathcal{X}_i,\lambda)$</span> by assumption of the model:</p><p class="math-container">\[\ell(y_i \mid \mathcal{X}_i, \lambda, x_i, m) = q_i(y_i\mid m(\mathcal{X}_i, \lambda))\]</p><h2 id="No-x-uncertainty"><a class="docs-heading-anchor" href="#No-x-uncertainty">No <span>$x$</span>-uncertainty</a><a id="No-x-uncertainty-1"></a><a class="docs-heading-anchor-permalink" href="#No-x-uncertainty" title="Permalink"></a></h2><p>A convenient situation is, when the distinction between <span>$x_i$</span> and <span>$\mathcal{X}_i$</span> can be neglected, e.g. because the independent variable can be measured with high precision. Then <span>$p_i(\mathcal{X}_i\mid \lambda, x_i, m)$</span> becomes a Dirac distribution, and</p><p class="math-container">\[\ell(y_i\mid \lambda, x_i, m) = q(y_i\mid m(x_i,\lambda))\]</p><p>Hence, the posterior probability reads </p><p class="math-container">\[p(\lambda \mid \{x_i\}_{i=1}^N, \{y_i\}_{i=1}^N, m) \propto  p_0(\lambda\mid \{x_i\}_{i=1}^N, m) \prod_{i_1}^n q_i(y_i\mid m(x_i,\lambda))\]</p><h2 id="Retrieving-the-LSQ-objective"><a class="docs-heading-anchor" href="#Retrieving-the-LSQ-objective">Retrieving the LSQ objective</a><a id="Retrieving-the-LSQ-objective-1"></a><a class="docs-heading-anchor-permalink" href="#Retrieving-the-LSQ-objective" title="Permalink"></a></h2><p>Using the aforementioned uniform prior <span>$p_0(\lambda\mid \{x_i\}_{i=1}^N, m) = 1$</span> and assuming normal distributions for <span>$q_i$</span> with standard deviations <span>$\Delta y_i$</span> leads to</p><p class="math-container">\[\begin{aligned}
p(\lambda \mid \{x_i\}_{i=1}^N, \{y_i\}_{i=1}^N, m) &amp;\propto   \prod_{i_1}^n \frac{1}{\sqrt{2\pi}\Delta y_i}\exp\left(- \frac{(y_i - m(x_i,\lambda))^2}{2\Delta y_i}\right) \\ 
&amp;\propto \prod_{i_1}^n \exp\left(- \frac{(y_i - m(x_i,\lambda))^2}{2\Delta y_i}\right)\\ 
&amp; \quad = \exp\left(- \sum_{i=1}^N \frac{(y_i - m(x_i,\lambda))^2}{2\Delta y_i}\right)
\end{aligned}\]</p><p>Maximizing this function is equivalent to minimizing</p><p class="math-container">\[\sum_{i=1}^N \frac{(y_i - m(x_i,\lambda))^2}{2\Delta y_i}\]</p><p>which is the weighted least squares objective (up to a factor <span>$\frac{1}{2}$</span>) function (see <a href="../lsq_background/#Background:-LSQ">Background: LSQ</a>).</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../lsq_implementation/">« How to implement</a><a class="docs-footer-nextpage" href="../posterior_implementation/">How to implement »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.3.0 on <span class="colophon-date" title="Wednesday 10 July 2024 23:10">Wednesday 10 July 2024</span>. Using Julia version 1.10.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
